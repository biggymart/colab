{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChaptchaRecognition.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN2uPJ3hIFV3BQAAwdP5cgF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/biggymart/colab/blob/main/ChaptchaRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Cap_Ftx4LpC"
      },
      "source": [
        "https://www.youtube.com/watch?v=IcLEJB2pY2Y&t=1052s\n",
        "\n",
        "Title: Captcha recognition using PyTorch (Convolutional-RNN + CTC Loss)\n",
        "\n",
        "Book: Approaching (Almost) Any Machine Learning Problem (Abhishek Thakur)\n",
        "\n",
        "cf> for Keras version of it, refer to: https://keras.io/examples/vision/captcha_ocr/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7x31EUZEWsQ"
      },
      "source": [
        "모르는 부분 list-up:\n",
        "1.   albumentation, .Compose\n",
        "2.   np.transpose(2, 0, 1)\n",
        "3.   glob\n",
        "4.   list in a list (list comprehension)\n",
        "5.   label encoder\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Sx8B7hawowI"
      },
      "source": [
        "# config.py\n",
        "\n",
        "DATA_DIR = '../input/captcha_images_v2'\n",
        "BATCH_SIZE = 8\n",
        "IMAGE_WIDTH = 300\n",
        "IMAGE_HEIGHT = 75\n",
        "NUM_WORKERS = 8\n",
        "EPOCHS = 200\n",
        "DEVICE = \"cuda\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNirUY9c8-lo"
      },
      "source": [
        "captcha 데이터셋을 보면, png 이미지들이 있음을 확인할 수 있음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap79ybadwHIg"
      },
      "source": [
        "# dataset.py\n",
        "\n",
        "import albumentations # for augmentation\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image # to read image\n",
        "from PIL import ImageFile\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "class Classification:\n",
        "  def __init__(self, image_paths, targets, resize=None):\n",
        "    # resize: (h, w)\n",
        "    self.image_paths = image_paths\n",
        "    self.targets = targets\n",
        "    self.resize = resize\n",
        "    self.aug = albumentation.Compose([albumentations.Normalize(always_apply=True)])\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.image_paths)\n",
        "\n",
        "  # this part is different from the keras tutorial\n",
        "  def __getitem__(self, item):\n",
        "    image = Image.open(self.image_paths[item]).convert(\"RGB\")\n",
        "    targets = self.targets[item]\n",
        "\n",
        "    if self.resize is not None:\n",
        "      image = image.resize(\n",
        "          (self.resize[1], self.resize[0]), resample=Image.BILINEAR\n",
        "         )\n",
        "\n",
        "    image = np.array(image)\n",
        "    augmented = self.aug(image=image)\n",
        "    image = augmented[\"image\"]\n",
        "    image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
        "    return {\n",
        "        \"images\": torch.tensor(image, dtype=torch.float),\n",
        "        \"targets\": torch.tensor(targets, dtype=torch.long)\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAQ4Q3CUAgIA"
      },
      "source": [
        "# train.py\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "\n",
        "import config\n",
        "import dataset\n",
        "\n",
        "# you can also grab all the images and create csv\n",
        "# but it is not implemented here\n",
        "def run_training():\n",
        "  image_files = glob.glob(os.path.join(config.DATA_DIR, \"*.png\"))\n",
        "  # \"/../.../whatever.png\" -> last element: \"whatever.png\" -> crop until last 4: \"whatever\"\n",
        "  targets_orig = [x.split(\"/\")[-1][:4] for x in image_files]\n",
        "  # if your targets were \"abcde\" -> it becomes targets_flat = ['a', 'b', 'c', 'd', 'e']\n",
        "  # list in a list\n",
        "  targets = [[c for c in x] for x in targets_orig]\n",
        "  targets_flat = [c for clist in targets for c in clist]\n",
        "\n",
        "  lbl_enc = preprocessing.LabelEncoder()\n",
        "  lbl_enc.fit(targets_flat)\n",
        "  # we want to create an encoded target\n",
        "  targets_enc = [lbl_enc.transform(x) for x in targets]\n",
        "  targets_enc = np.array(targets_enc) + 1 # encoding starts with 0 and we want to keep 0 for unknown\n",
        "  print(targets_enc)\n",
        "  print(len(lbl_enc.classes_))\n",
        "  print(np.unique(targets_flat))\n",
        "\n",
        "  train_imgs, test_imgs, train_targets, test_targets, train_orig_targets, test_orig_targets = model_selection.train_test_split(image_files, targets_enc, targets_orig, test_size=0.1, random_state=42)\n",
        "  train_dataset = dataset.ClassificationDataset(image_paths=train_imgs, targets=train_targets, resize(config.IMAGE_HEIGHT, config.IMAGE_WIDTH))\n",
        "\n",
        "\n",
        "if __name__ -- \"__main__\":\n",
        "  run_training()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}